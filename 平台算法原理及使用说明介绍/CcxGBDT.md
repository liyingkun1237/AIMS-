## 4.5 CcxGBDT

#### CcxGBDT梯度提升树算法原理

​	Gradient Boosting Decision Tree是一种基于梯度提升的加强学习算法，属于boosting算法族的一部分。GBDT通过多轮迭代，每轮产生一个弱分类器，每个分类器在上一轮分类器的残差基础上进行训练，通过不断迭代训练来降低偏差提高最终分类器的精度。弱分类器一般选择CART分类回归树，迭代过程中假设前一轮得到的强学习器是![img](function_tools/wps3C0A.tmp.png)，损失函数是![img](function_tools/wps3C0B.tmp.png)；本轮是利用损失函数的负梯度![img](function_tools/wps3C1B.tmp.png)来拟合损失的近似值，得到一个弱学习器![img](function_tools/wps3C1C.tmp.png)，使得本轮损失函数![img](function_tools/wps3C2D.tmp.png)最小，样本损失尽量最小。

算法基本流程如下：

1）初始化弱学习器：![img](function_tools/wps3C2E.tmp.png)；

2）对迭代轮数有m=1,2,…,M，计算负梯度及残差：

![img](function_tools/wps3C3F.tmp.png)；

3）将上一步得到的残差作为新的真实值，并将数据![img](function_tools/wps3C40.tmp.png)，i=1,2,…,N作为下一棵树的训练数据，得到一颗新的回归树![img](function_tools/wps3C50.tmp.png)其对应的叶子节点区域为![img](function_tools/wps3C51.tmp.png)，j=1,2,…,J；

4）对叶子区域![img](function_tools/wps3C62.tmp.png)，计算最佳拟合值：

![img](function_tools/wps3C63.tmp.png)；

5）得到最终强学习器：![img](function_tools/wps3C64.tmp.png)。

#### CcxGBDT使用建议

- GBDT可以很好的处理缺失特征，决策树的每个节点只依赖一个特征，如果某个特征不存在，这颗树依然可以做决策，只是少了一些路径。
- GBDT灵活处理各种特征数据类型，包括连续值和离散值。适合处理低维数据，如果数据维度比较高时会加大算法的计算复杂度。
- GBDT使用一些健壮额损失函数，对异常值的鲁棒性很强。比如Huber损失函数和Quantitle损失函数。

#### CcxGBDT模型超参数设置

- **数据划分**：系统提供了分层抽样和随机抽样两种数据划分方法；
- **测试集比例**：用于分配模型训练中训练样本与测试样本的比例；

- **min_samples_split**：万象智模平台默认值2，内部节点再划分所需最小样本数。这个值限制子树继续划分的条件，如果某节点的样本数少于min_samples_split，则不会继续再尝试选择最优特征来进行划分。如果样本量不大，可以不考虑这个值。如果样本数量级非常大，则推荐增大这个值。

- **min_weight_fraction_leaf**：万象智模平台默认值0，子结点最小的样本权重和，这个值限制了叶子节点所有样本权重和的最小值，如果小于这个值，则会和兄弟节点一起被剪枝。一般来说，如果较多样本有缺失值，或者分类树样本的分布类别偏差较大，则应引入样本权重，注意该值的设置。

- **max_depth**：万象智模平台默认值5，决策树最大深度。一般来说，对于数据或者特征少的时候，可以不考虑这个值。但如果模型样本数量多，特征多的时候，则推荐限制这个最大深度，具体取值取决于数据的分布。建议取值范围3-10。

- **n_estimators**：万象智模平台默认值100，取值范围[1,inf]，最大的基学习器的个数取值太小，容易欠拟合，取值太大，计算量会太大，并且最大的基学习器的个数到一定的数量后，再增大其取值获得的模型提升会很小，所以一般选择一个适中的数值。而在实际调参过程中，常常与learning_rate一起考虑。

- **max_features**：万象智模平台默认值0.5，表示最大特征数选取50%的特征。如果是"log2"意味着划分时最多考虑log2N个特征；如果是"sqrt"或者"auto"意味着划分时最多考虑√N个特征。如果是整数，代表考虑的特征绝对数。如果是浮点数，代表考虑特征百分比，即考虑(百分比xN)取整后的特征数。其中N为样本总特征数。一般来说，如果样本特征数不多，比如小于50，我们用默认的”None”就可以了，如果特征数非常多，我们可以通过设置参数值来控制划分时考虑的最大特征数，以控制决策树的生成时间。

- **learning_rate**：万象智模平台默认值0.1，取值范围[0,1]，建议取值0.01-0.3。学习率通过减少每一步的权重，提高模型的鲁棒性。对于同样的训练集拟合效果，较小的步长意味着需要更多的迭代次数。通常采用learning_rate和n_estimators共同进行调参，一起决定算法的拟合效果。

- **寻优策略**

  - **init_points**：万象智模平台默认值为2，确定寻优方式后，算法对应的模型超参数组合的初始个数。

  - **num_iter**：万象智模平台默认值为5，寻优算法的迭代次数。

- **最优选择指标**

  - **测试集auc最优**：最优模型选择标准为测试集上模型的评估指标auc最大。

  - **测试集/训练集auc综合最优**：最优模型选择标准为综合测试集和训练集上模型的评估指标auc最大。