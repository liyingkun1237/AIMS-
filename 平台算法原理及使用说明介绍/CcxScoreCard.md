## 4.1 CcxScoreCard

#### CcxScoreCard评分卡算法原理

​	标准评分卡模型的开发基于逻辑回归，逻辑回归(Logistic Regression)是机器学习中的一种分类模型，是业界常用的监督学习算法，由于算法的简单和高效，在实际中应用非常广泛。如：在广告投放中，判断用户是否会点击广告，营销领域判断用户是否会购买，风控领域判断用户是否会违约等场景。这里以是否违约为例介绍逻辑回归算法的原理。发生违约的概率记为P(y=1)=p则逻辑回归模型可以表示为：

![公式4.1](function_tools/4.1.png)

​	即有：![公式4.2](function_tools/4.2.png)

​	当![Z](function_tools/Z.png)趋于![正无穷](function_tools/%E6%AD%A3%E6%97%A0%E7%A9%B7.png)时，![P](function_tools/P.png)值渐近于1；当![Z](function_tools/Z.png)趋于![负无穷](function_tools/%E8%B4%9F%E6%97%A0%E7%A9%B7.png)时，![P](function_tools/P.png)值渐近于0，将![负无穷到正无穷](function_tools/%E6%AD%A3%E8%B4%9F%E6%97%A0%E7%A9%B7.png)通过转换映射到[0，1]之间。逻辑回归模型的参数估计通常采用最大似然估计，即找到一组参数，使得在这组参数下，似然函数最大。对数似然函数为：

![公式4.3](function_tools/4.3.png)

​	在上述的优化问题中，存在多种求解方法，这里以梯度下降为例说明。梯度下降(Gradient Descent)又称为最速梯度下降，是一种迭代求解的方法，通过在每一步选取使目标函数变化最快的一个方向调整参数的值来逼近最优值。

基本步骤如下：

- 选择下降方向，即梯度方向

- 选择步长，更新参数

- 重复以上两步直到满足终止条件

得到回归参数的学习规则：![公式4.4](function_tools/4.4.png)

#### 标准评分卡的开发流程

在标准开发流程基础上，万象智模平台评分卡模型的开发流程如下：

<div align=center><img width = '800' height ='400' src="../images/评分卡.jpg" /></div>

​	在建模中，需要对连续变量离散化(即变量分箱)，特征离散化后，模型会更稳定，降低了模型过拟合的风险。万象智模平台提供了多种变量分箱的方法，按变量类型分为连续型变量分箱和离散型变量分箱；常见的等频分箱、等宽分箱、卡方分箱和决策树分箱都属于连续型变量的分箱方式；离散型变量的分箱方式包括聚类分箱和违约率分箱两种。

#### 变量分箱方式

假设要将某个变量的观测值分为k个分箱，常见的分箱方法有：

- **等宽分箱**：将变量的取值范围等宽的分为k个区间，每个区间作为一个分箱

- **等频分箱**：将变量取值按照从小到大的顺序排列，根据取值个数等分为k个部分，每部分作为一个分箱

- **卡方分箱**：卡方分箱法是自底向上基于合并的数据离散化方法，它依赖于卡方检验，具有最小卡方值的相邻区间合并在一起，直到满足确定的停止规则。卡方分箱法的基本思想是对于精确的离散化，相对类频率在一个区间内应当完全一致。因此，如果两个相邻的区间具有非常类似的类分布，则这两个区间可以合并，低卡方值表明具有相似的类分布，卡方分箱中有两个参数需要设置：

  - **max_intervals**：最大的取值个数，当连续变量的取值个数大于max_intervals时才进行卡方分箱，万象智慧平台默认取值为10

  - **threshold**：卡方阈值，当变量两区间的卡方值小于等于threshold时才进行合并，万象智模平台默认取值为5(根据显著性水平和自由度得到卡方值，自由度=1 & 显著性水平=0.025时，即97.5%置信度下，卡方值=5)。

  类别和属性独立时，有97.5%的可能性，计算得到的卡方值会小于5。大于阈值5的卡方值就说明属性和类不是相互独立的，如果阈值选的大，区间合并就会进行很多次，离散后的区间数量少、区间大。

- **决策树分箱**：决策树分箱采用的是自顶向下的贪婪算法，它会在每个节点选择分类效果最好的属性对样本进行二分类，然后继续这个过程，直到这棵树能够准确的分类训练样本，或者所有的属性都已被用过。决策树算法的核心是在对每个结点进行测试后，选择最佳的属性，并且对决策树进行剪枝处理。这里的剪枝是预剪枝，所谓预剪枝，就是让决策树在生长之前，就定好树的层数，以及每个节点所允许的最少的样本数量，从而达到防止过拟合的效果，通过如下两个参数实现：

  - **max_depth**：决策树的层数，设置为3，表明决策树最多生成8个叶子节点，即变量最多分8箱；

  - **min_samples_leaf**：叶子节点中最少的样本比例或样本数量，设置为0.05，表明每个叶子节点中的样本数量不能少于训练样本的5%，即变量每一箱的样本量不少于训练样本的5%。

- **聚类分箱**：采用k均值聚类方法将变量值聚为k类，但在聚类过程中需要保证分箱的有序性，第一个分箱中的所有变量值都要小于第二个分箱中的变量值，第二个分箱中的所有变量值都要小于第三个分箱中的变量值等
- **违约率分箱**：按照违约率对变量进行分箱的一种方式，将该变量所有样本对应违约率的取值范围等分为k个区间，然后根据所属不同的违约率取值区间对样本进行合箱，最后将每个区间作为一个分箱

#### 评分卡使用建议

​	标准评分卡模型通常为需要模型变量在业务上具有可解释性的场景，用户只需要按照要求输入数据，便可得到评分卡输出。

#### 评分卡参数设置

​	由于评分卡流程中，各步骤的实现方法有多种，且对于连续变量和分类变量的处理存在较大差异，因此按照评分卡流程中需对各步骤方法进行详细的参数设置说明。具体参数设置步骤如下：

- **数据划分**：系统提供了分层抽样和随机抽样两种数据划分方法

- **测试集比例**：用于分配模型训练中训练样本与测试样本的比例

- **缺失值处理**：缺失值处理包含两个阈值参数和填充方式的设置

  - **UpperLmt**：样本缺失率大于阈值UpperLmt时，删除对应变量

  - **LowerLmt**：样本缺失率小于阈值LowerLmt时，进行缺失值填充

  - **填充方式**：针对连续型变量有中位数、均值和众数三种填充方式；针对离散型变量采用众数进行填充

注：对于样本缺失率介于UpperLmt和LowerLmt的变量，其缺失值默认填充为missing，分箱时作为单独的一箱处理。

- **变量分箱**

  - **卡方分箱**

    - **max_intervals**：最大的取值个数，当连续变量的取值个数大于max_intervals时才进行卡方分箱，万象智模平台默认取值为10

    - **threshold**：卡方阈值，当变量两区间的卡方值小于等于threshold时才进行合并，万象智模平台默认取值为5

  - **决策树分箱**
    - **max_depth**：决策树的层数，设置为3
    - **min_samples_leaf**：叶子节点中最少的样本比例或样本数量，设置为0.05

- **特征筛选**

  - VIF筛选的阈值为10，变量VIF>10时，剔除
  - IV值筛选的阈值为0.02，变量IV值<0.02时，剔除
  - 逐步回归筛选变量
    - **back_step_reg**：向后逐步回归，将所有变量用于建模，每一步剔除P值最大的变量，直到所有的变量都满足条件为止，一旦某个变量被从模型中移除，将不会再被纳入
    - **fwd_step_reg**：向前逐步回归，每一步检验没有纳入模型的变量并选择P值最小且满足条件的变量进入模型，直到所有变量被纳入模型或没有变量满足为止，一旦变量被纳入模型，将不会再被移除
    - **two_way_reg**：双向逐步回归是结合前向和后向的选择法，每一步用前向选择增加最优的变量，用后向选择剔除最差的变量，逐步选择法给每一个变量被纳入模型的机会，又允许在前期被纳入模型的变量被移出模型，直到模型中所有的变量都是显著的，剔除的变量都是不显著的

#### 评分转换

评分转换公式：Score = A - B*ln(ODDS)

- **BaseScore**：基准分，ODDS=1时对应的评分分值，即A的取值

- **PDO**：违约率翻一倍，评分下降的分值数

